{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Non_Representative_Statistics_Estimation_Smells.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1XEhbtlu5GwZ3YsvePw8HRJQPIsKgOHtb",
      "authorship_tag": "ABX9TyPGsCgHtbx07wzxTeiatOHT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeedsiddik/dl_design_smells/blob/main/Non_Representative_Statistics_Estimation_Smells.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1N4nB_IkXj4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "import glob, os\n",
        "import pandas as pd\n",
        "from fnmatch import fnmatch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to gDrive and get list of files"
      ],
      "metadata": {
        "id": "i8udyI7G0rEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmfjsPz3ksrP",
        "outputId": "b38d5ddf-7702-40df-8319-df7d08f6b104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_path = \"/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/\""
      ],
      "metadata": {
        "id": "8ohfAw7WzNtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_list_of_filename(path, extension):\n",
        "#     notebook_filenames_list = glob.glob(os.path.join(path, extension))\n",
        "    \n",
        "#     print(len(notebook_filenames_list))\n",
        "#     return notebook_filenames_list"
      ],
      "metadata": {
        "id": "PD-VtCVez2eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_of_filename(root, extension):\n",
        "    target_filenames_list = []\n",
        "\n",
        "    for path, subdirs, files in os.walk(root):\n",
        "        for name in files:\n",
        "            if fnmatch(name, extension):\n",
        "                target_filenames_list.append(os.path.join(path, name))\n",
        "\n",
        "    print (\"Total files: \", (len(target_filenames_list)))\n",
        "    return target_filenames_list"
      ],
      "metadata": {
        "id": "xcQtv-JgnjkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_py_files = get_list_of_filename(gdrive_path+\"data/\", \"*.py\")\n",
        "list_of_py_files"
      ],
      "metadata": {
        "id": "wEzJVWbzz6jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detect BatchNormalization and Dropout in DL Code "
      ],
      "metadata": {
        "id": "Nzj9YDfX0w3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name_list, code_line_list, line_number_list = [], [], []\n",
        "for filename in list_of_py_files:\n",
        "    try:\n",
        "        with open(filename) as fp:\n",
        "            is_dl_project = False\n",
        "            line_number = 0\n",
        "            \n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                line_number += 1\n",
        "                line = line.strip()\n",
        "                if re.match(r'^from |import ', line):\n",
        "                    package_name = line.split()[1].split('.')[0]\n",
        "                    if re.match(r'keras|tensorflow', package_name):\n",
        "                        is_dl_project = True\n",
        "                \n",
        "                if (is_dl_project):\n",
        "                    if (\"BatchNormalization()\" in line) or (\"Dropout(\" in line):\n",
        "                        file_name_list.append(filename)\n",
        "                        code_line_list.append(line)\n",
        "                        line_number_list.append(line_number)\n",
        "                        \n",
        "                        # print (filename, line_number, line)\n",
        "    except Exception as e:\n",
        "        print(\"Error : \", filename, \"; \", str(e))\n",
        "        pass \n"
      ],
      "metadata": {
        "id": "61jUVs6p0K7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Filename':file_name_list, 'Code': code_line_list, 'LineNumber':line_number_list}\n",
        "df_dl_smell = pd.DataFrame(data)\n",
        "df_dl_smell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fLqCDjPV0MxF",
        "outputId": "0a2412ad-9547-4757-9dbe-8897372d43a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Filename  \\\n",
              "0    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "1    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "2    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "3    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "4    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "..                                                 ...   \n",
              "937  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "938  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "939  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "940  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "941  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "\n",
              "                                Code  LineNumber  \n",
              "0    model.add(BatchNormalization())          12  \n",
              "1            model.add(Dropout(0.5))          14  \n",
              "2    model.add(BatchNormalization())          18  \n",
              "3            model.add(Dropout(0.5))          20  \n",
              "4    model.add(BatchNormalization())          24  \n",
              "..                               ...         ...  \n",
              "937            BatchNormalization(),          94  \n",
              "938            BatchNormalization(),          98  \n",
              "939           Dropout(dropout_rate),         102  \n",
              "940            BatchNormalization(),         105  \n",
              "941            BatchNormalization(),         109  \n",
              "\n",
              "[942 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-449de058-db81-452d-a365-76b19528a6a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Code</th>\n",
              "      <th>LineNumber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(BatchNormalization())</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(Dropout(0.5))</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(BatchNormalization())</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(Dropout(0.5))</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(BatchNormalization())</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>BatchNormalization(),</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>BatchNormalization(),</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>Dropout(dropout_rate),</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>BatchNormalization(),</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>BatchNormalization(),</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>942 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-449de058-db81-452d-a365-76b19528a6a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-449de058-db81-452d-a365-76b19528a6a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-449de058-db81-452d-a365-76b19528a6a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.unique(df_dl_smell['Filename'])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UEGW87QR1G_I",
        "outputId": "c4eccf3e-58a7-4eac-e399-b84880622fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so34716454.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(pd.unique(df_dl_smell['Filename'])[0]) as f:\n",
        "    lines = f.readlines()\n",
        "content = ''.join(lines)\n",
        "\n",
        "lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW6uSXAD1TRw",
        "outputId": "994c0946-1c24-4e43-d15c-af5c86906650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# import BatchNormalization\\n',\n",
              " 'from tensorflow.keras.layers import BatchNormalization\\n',\n",
              " 'from keras.models import Sequential\\n',\n",
              " 'from tensorflow.keras.layers import Dense\\n',\n",
              " 'import tensorflow as ts\\n',\n",
              " '\\n',\n",
              " '# instantiate model\\n',\n",
              " 'model = Sequential()\\n',\n",
              " '\\n',\n",
              " '# we can think of this chunk as the input layer\\n',\n",
              " \"model.add(Dense(64, input_dim=14, init='uniform'))\\n\",\n",
              " 'model.add(BatchNormalization())\\n',\n",
              " \"model.add(Activation('tanh'))\\n\",\n",
              " 'model.add(Dropout(0.5))\\n',\n",
              " '\\n',\n",
              " '# we can think of this chunk as the hidden layer    \\n',\n",
              " \"model.add(Dense(64, init='uniform'))\\n\",\n",
              " 'model.add(BatchNormalization())\\n',\n",
              " \"model.add(Activation('tanh'))\\n\",\n",
              " 'model.add(Dropout(0.5))\\n',\n",
              " '\\n',\n",
              " '# we can think of this chunk as the output layer\\n',\n",
              " \"model.add(Dense(2, init='uniform'))\\n\",\n",
              " 'model.add(BatchNormalization())\\n',\n",
              " \"model.add(Activation('softmax'))\\n\",\n",
              " '\\n',\n",
              " '# setting up the optimization of our weights \\n',\n",
              " 'sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\\n',\n",
              " \"model.compile(loss='binary_crossentropy', optimizer=sgd)\\n\",\n",
              " '\\n',\n",
              " '# running the fitting\\n',\n",
              " 'model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AST Python\n"
      ],
      "metadata": {
        "id": "w1JikkWo0jRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "from pprint import pprint\n",
        "\n",
        "# from find_call import FindCall\n",
        "from ast import NodeVisitor, literal_eval"
      ],
      "metadata": {
        "id": "VonXjJ7L0n62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FindCall(NodeVisitor):\n",
        "    def __init__(self, *args):\n",
        "        if len(args) < 1:\n",
        "            raise ValueError(\"No target function (need at least one)\")\n",
        "        self.result = {arg: []for arg in args}\n",
        "\n",
        "    def visit_Call(self, node):\n",
        "        if hasattr(node.func, \"id\") and (node.func.id in self.result):\n",
        "            self.result[node.func.id].append([node.lineno])\n",
        "        # visit the children\n",
        "        self.generic_visit(node)"
      ],
      "metadata": {
        "id": "GI02Xjdj0rQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_py_files = get_list_of_filename(gdrive_path+\"data/\", \"*.py\")\n",
        "# list_of_py_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiLsA89XSPfk",
        "outputId": "b5a2e68e-0f26-4f25-8d93-2e2d2d4f1a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files:  204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter the .py files \n",
        "\n",
        "Select files conatining \"BatchNormalization\", \"Dropout\" functions.  "
      ],
      "metadata": {
        "id": "jCGlWCWMtpSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "method_names = [\"BatchNormalization\", \"Dropout\"]\n",
        "\n",
        "list_of_ast_filenames = []\n",
        "list_of_ast_method_dict = []\n",
        "\n",
        "for file_name in list_of_py_files:\n",
        "    try:\n",
        "        file = open(file_name, 'r')\n",
        "        ast_data = ast.parse(file.read())\n",
        "\n",
        "        intra_file_ast_method_dict = []\n",
        "        atleast_one_methods_used = True\n",
        "\n",
        "        for method_name in method_names:\n",
        "            fc = FindCall(method_name)\n",
        "            fc.visit(ast_data)\n",
        "            # print (fc.result.keys())\n",
        "            # print ((\"Keys %s: Values %s, Len %s\")%(fc.result.keys(), fc.result.values(), len(fc.result.values() ) ))\n",
        "\n",
        "            atleast_one_methods_used = bool([a for a in fc.result.values() if a != []])\n",
        "                \n",
        "            intra_file_ast_method_dict.append(fc.result)\n",
        "\n",
        "        if(atleast_one_methods_used):\n",
        "            list_of_ast_filenames.append(file_name)\n",
        "            list_of_ast_method_dict.append(intra_file_ast_method_dict)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print (\"Problem in AST: Filename \" + file_name + \":  \" + str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo1C1OXGC6Te",
        "outputId": "d1f7cf6e-9872-46e7-86be-34c604521ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem in AST: Filename /content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Deep-Learning-for-ECoG.git/rtfm_psdP2P_all.py:  invalid syntax (<unknown>, line 114)\n",
            "Problem in AST: Filename /content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Forecasting-Air-Pollutant-Concentration-in-Lille.git/preprocess.py:  unexpected indent (<unknown>, line 13)\n",
            "Problem in AST: Filename /content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Forecasting-Air-Pollutant-Concentration-in-Lille.git/trainer.py:  invalid syntax (<unknown>, line 22)\n",
            "Problem in AST: Filename /content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tws-segnet.git/src/gdal2tiles.py:  Missing parentheses in call to 'print'. Did you mean print('You are using \"old gen\" bindings. gdal2tiles needs \"new gen\" bindings.')? (<unknown>, line 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting Non-representative Statistics Estimation. \n",
        "\n",
        "Bad smell regarding regularizations is using batchnorm after dropout."
      ],
      "metadata": {
        "id": "AH6HIZcptZSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"------ Non Representative Statistical Estimation Found --------\")\n",
        "for file_wise_method_line, ast_filename in zip(list_of_ast_method_dict, list_of_ast_filenames):\n",
        "    batchNormal_lines, dropout_lines = [], []\n",
        "\n",
        "    for method_line_dict in file_wise_method_line:\n",
        "        for key, value in method_line_dict.items():\n",
        "            # print (key, len(value), value)\n",
        "            if (key=='BatchNormalization'):\n",
        "                batchNormal_lines = value\n",
        "            else:\n",
        "                dropout_lines = value \n",
        "    \n",
        "    if ((len(batchNormal_lines)) > 0 and (len(dropout_lines) > 0) ):\n",
        "        if batchNormal_lines[0] > dropout_lines[0]:\n",
        "            print (ast_filename, \"BatchNormalization:\", batchNormal_lines, \"Dropout:\", dropout_lines)\n",
        "        # print (\"BatchNormalization:\", batchNormal_lines, \" \\nDropout:\", dropout_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijtJw9nReWVe",
        "outputId": "dd8c8aae-c9af-4c9a-9202-3498713dea5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ Non Representative Statistical Estimation Found --------\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so55776436_2.py BatchNormalization: [[7]] Dropout: [[6]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so55776436_1.py BatchNormalization: [[7]] Dropout: [[6]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/kaggle_planet_competition.git/model/model_factory.py BatchNormalization: [[24], [31], [36], [81], [84], [87], [90], [98], [101], [104], [112], [115], [130], [323], [342], [361], [364], [383], [402], [421], [488], [519], [544], [569], [594], [619], [644], [658], [684], [701], [718], [735], [925], [980], [1017], [1054], [1091], [1128], [1165], [1203], [1245], [1279], [1313], [1342], [1346], [1355], [1395], [1435], [1475], [1518], [1546], [1582], [1590], [1592], [1598], [1604], [1610], [1616], [1623], [1631], [1635], [1641], [1647], [1653], [1664], [1672], [1676], [1682], [1688], [1705], [1713], [1748], [1757], [1790], [1799], [1832], [1842], [1863], [1874], [1895], [1906], [1933], [1944], [1977], [1988], [2021], [2032], [2071], [2082], [2111], [2122], [2151], [2162], [2191], [2200], [2226], [2236], [2262], [2266], [2276], [2302], [2306], [2316]] Dropout: [[18], [25], [126], [131], [287], [292], [302], [307], [324], [343], [362], [365], [384], [403], [422], [489], [520], [545], [570], [595], [620], [645], [659], [661], [685], [687], [702], [704], [719], [721], [736], [759], [782], [805], [892], [914], [985], [990], [995], [1000], [1022], [1027], [1032], [1037], [1059], [1064], [1069], [1074], [1096], [1101], [1106], [1111], [1133], [1138], [1143], [1148], [1170], [1175], [1180], [1185], [1208], [1213], [1218], [1250], [1255], [1260], [1265], [1284], [1289], [1294], [1299], [1317], [1322], [1327], [1332], [1337], [1343], [1347], [1360], [1365], [1370], [1375], [1380], [1385], [1400], [1405], [1410], [1415], [1420], [1425], [1440], [1445], [1450], [1455], [1460], [1465], [1480], [1485], [1490], [1495], [1500], [1505], [1522], [1527], [1532], [1537], [1542], [1547], [1558], [1563], [1568], [1573], [1578], [1583], [1595], [1601], [1607], [1613], [1619], [1624], [1636], [1642], [1648], [1654], [1660], [1665], [1677], [1683], [1689], [1695], [1701], [1706], [1718], [1723], [1728], [1733], [1738], [1743], [1749], [1761], [1766], [1771], [1776], [1781], [1786], [1791], [1803], [1808], [1813], [1818], [1823], [1828], [1833], [1847], [1853], [1859], [1864], [1879], [1885], [1891], [1896], [1911], [1917], [1923], [1929], [1934], [1949], [1955], [1961], [1967], [1973], [1978], [1993], [1999], [2005], [2011], [2017], [2022], [2037], [2043], [2049], [2055], [2061], [2067], [2072], [2087], [2092], [2097], [2102], [2107], [2112], [2127], [2132], [2137], [2142], [2147], [2152], [2167], [2172], [2177], [2182], [2187], [2192], [2204], [2208], [2212], [2216], [2221], [2227], [2240], [2244], [2248], [2252], [2257], [2263], [2267], [2280], [2284], [2288], [2292], [2297], [2303], [2307], [2320], [2324], [2328], [2332]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Forecasting-Air-Pollutant-Concentration-in-Lille.git/models/resnet.py BatchNormalization: [[21], [31], [40]] Dropout: [[14], [22], [32], [41]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GitHub Clone for Dataset  "
      ],
      "metadata": {
        "id": "_VlRxivJ08XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install PyGithub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f66SeAuB1OuS",
        "outputId": "691f6415-c19f-4e5f-fa78-9ae29e15d6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.9 gitpython-3.1.27 smmap-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gitpython"
      ],
      "metadata": {
        "id": "BHyzawQUjliF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98359eb-af6a-4953-a229-16c816860415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 71 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 102 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 133 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 143 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 174 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 181 kB 22.3 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30 kB 49.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 40 kB 54.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51 kB 58.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 61 kB 64.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.9 gitpython-3.1.27 smmap-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from git import Repo\n",
        "import shutil"
      ],
      "metadata": {
        "id": "JQzckUAmjbNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (os.path.isdir(gdrive_path+\"/data/\"+\"test\"))\n",
        "if (os.path.isdir(gdrive_path+\"/data/\"+\"test\")):\n",
        "    shutil.rmtree(gdrive_path+\"/data/\"+\"test\") \n",
        "\n",
        "print (os.path.isdir(gdrive_path+\"/data/\"+\"test\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Oz2InIQut0j",
        "outputId": "a054353c-8b6f-4acf-8f26-9f6cdc1a9a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(gdrive_path+'/data/github_data_link.txt', 'r')\n",
        "lines = file.readlines()\n",
        "\n",
        "for git_url in lines:\n",
        "    try:\n",
        "        git_url = git_url.strip()\n",
        "        repo_dir = gdrive_path+\"/data/\"+git_url.split(\"/\")[-1]\n",
        "\n",
        "        # remove the directory if it already exists and replace wit the new one\n",
        "        if (os.path.isdir(repo_dir)):\n",
        "            shutil.rmtree(repo_dir) \n",
        "\n",
        "        Repo.clone_from(git_url, repo_dir)\n",
        "    except Exception as e:\n",
        "        print (\"Error in \"+ git_url + \"; \" + e)"
      ],
      "metadata": {
        "id": "9Snw4ZbemFAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Github clone target files "
      ],
      "metadata": {
        "id": "imrEVBpS_toh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "from pprint import pprint\n",
        "\n",
        "import requests\n",
        "from github import Github\n",
        "from github.GithubException import RateLimitExceededException\n",
        "from github.GithubObject import GithubObject\n",
        "from github.PaginatedList import PaginatedList"
      ],
      "metadata": {
        "id": "90W50ioG_0iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACCESS_TOKEN = \"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\""
      ],
      "metadata": {
        "id": "aA6EdAZj_4OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PAGE_SIZE = 100\n",
        "g = Github(ACCESS_TOKEN, per_page=PAGE_SIZE)\n",
        "\n",
        "\n",
        "def wait():\n",
        "    rate = g.get_rate_limit().search\n",
        "    reset_utc_timestamp = rate.reset.timestamp()\n",
        "    now_utc_timestamp = datetime.datetime.utcnow().timestamp()\n",
        "    sleep_time = (reset_utc_timestamp - now_utc_timestamp) + 5  # 5s buffer time\n",
        "    print(f\"Waiting {sleep_time}s to pass rate limit\")\n",
        "    time.sleep(sleep_time)\n",
        "\n",
        "\n",
        "def get_filename(file: GithubObject):\n",
        "    filename = os.path.join(file.repository.full_name, file.path)\n",
        "    filename = filename.replace('/', '$')\n",
        "    return filename.replace('\\\\', '$')\n",
        "\n",
        "\n",
        "def save_file(url: str, filename: str, count: int):\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "    directory = \"data/\"\n",
        "    if not os.path.exists(directory):\n",
        "        print(\"Path doesn't exists\")\n",
        "        os.mkdir(directory)\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    print(f\"[{count}] Saving {full_path}\")\n",
        "    open(full_path, 'wb').write(r.content)\n",
        "\n",
        "\n",
        "def save_files_of_page(codes, page_index, count):\n",
        "    page_codes = codes.get_page(page_index)\n",
        "    print(f\"{len(page_codes)} results in page {page_index+1}\")\n",
        "\n",
        "    for code in page_codes:\n",
        "        count += 1\n",
        "        save_file(code.download_url, get_filename(code), count)\n",
        "\n",
        "    return count\n",
        "\n",
        "\n",
        "def clone_files():\n",
        "    query = \"BatchNormalization Dropout keras in:file extension:py language:python\"\n",
        "    codes = g.search_code(query)\n",
        "    print(f\"Total {codes.totalCount} results found\")\n",
        "\n",
        "    count = 0\n",
        "    for page_index in range(10): # Allows to query 10 pages\n",
        "        try:\n",
        "            count = save_files_of_page(codes, page_index, count)\n",
        "            if count == codes.totalCount:\n",
        "                break\n",
        "        except RateLimitExceededException:\n",
        "            wait()\n",
        "            count = save_files_of_page(codes, page_index, count)\n",
        "            if count == codes.totalCount:\n",
        "                break\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    clone_files()"
      ],
      "metadata": {
        "id": "pm4zRYQO_6YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------- Practice ------------ "
      ],
      "metadata": {
        "id": "zT5k-TBVTvej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "from pprint import pprint\n",
        "\n",
        "import requests\n",
        "from github import Github\n",
        "from github.GithubException import RateLimitExceededException\n",
        "from github.GithubObject import GithubObject\n",
        "from github.PaginatedList import PaginatedList"
      ],
      "metadata": {
        "id": "HnrDTyon1B2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACCESS_TOKEN = \"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\""
      ],
      "metadata": {
        "id": "4fw6lYr340cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAGE_SIZE = 1\n",
        "g = Github(ACCESS_TOKEN, per_page=PAGE_SIZE)"
      ],
      "metadata": {
        "id": "4iMtfFq545eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wait():\n",
        "    rate = g.get_rate_limit().search\n",
        "    reset_utc_timestamp = rate.reset.timestamp()\n",
        "    now_utc_timestamp = datetime.datetime.utcnow().timestamp()\n",
        "    sleep_time = (reset_utc_timestamp - now_utc_timestamp) + 5  # 5s buffer time\n",
        "    print(f\"Waiting {sleep_time}s to pass rate limit\")\n",
        "    time.sleep(sleep_time)"
      ],
      "metadata": {
        "id": "Pdov8Az7496O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filename(file: GithubObject):\n",
        "    filename = os.path.join(file.repository.full_name, file.path)\n",
        "    filename = filename.replace('/', '$')\n",
        "    return filename.replace('\\\\', '$')"
      ],
      "metadata": {
        "id": "5jAE7f9a4_4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_file(url: str, filename: str, count: int):\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "    directory = gdrive_path + \"data/\"\n",
        "    if not os.path.exists(directory):\n",
        "        print(\"Path doesn't exists\")\n",
        "        os.mkdir(directory)\n",
        "\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    print(f\"[{count}] Saving {full_path}\")\n",
        "    open(full_path, 'wb').write(r.content)"
      ],
      "metadata": {
        "id": "pvDeWHc75Bz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.exists(gdrive_path + \"data/\")"
      ],
      "metadata": {
        "id": "LfxX0xgXATv1",
        "outputId": "a3c443fd-979f-4a11-977f-6d5bcd85f67e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_files_of_page(codes, page_index, count):\n",
        "    page_codes = codes.get_page(page_index)\n",
        "    print(f\"{len(page_codes)} results in page {page_index+1}\")\n",
        "\n",
        "    for code in page_codes:\n",
        "        count += 1\n",
        "        save_file(code.download_url, get_filename(code), count)\n",
        "\n",
        "    return "
      ],
      "metadata": {
        "id": "UH_bBriJ6rcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repositories = g.search_repositories(query='keras in:file extension:py language:python')\n",
        "# print (repositories.size())\n",
        "for repo in repositories:\n",
        "    print(repo)"
      ],
      "metadata": {
        "id": "ruWAXS_yCOku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the user provides the input you need to split into a list: Here, you are splitting the keywords provided and trimming them of any unnecessary white-space. Python’s list comprehensions enable you to perform all this in one line."
      ],
      "metadata": {
        "id": "b4CR2b9uNCQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = \"keras, tensorflow, BatchNormalization, Dropout\"\n",
        "# keywords =  \"french, german\"\n",
        "keywords = [keyword.strip() for keyword in keywords.split(',')]\n",
        "print(keywords)"
      ],
      "metadata": {
        "id": "cXWUoDbyK7x_",
        "outputId": "6b3efbfe-63db-43ce-a675-23bca1bed941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['keras', 'tensorflow', 'BatchNormalization', 'Dropout']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you need to add a function that will receive the keywords and search GitHub for repos that match."
      ],
      "metadata": {
        "id": "ZDyI646eNLXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There’s a couple of things happening in this function. First of all, you are taking the keywords and forming a GitHub search query. GitHub search queries taking the following format.\n",
        "\n",
        "SEARCH_KEYWORD_1+SEARCH_KEYWORD_N+QUALIFIER_1+QUALIFIER_N\n"
      ],
      "metadata": {
        "id": "PV2JWeJmNpas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_github(keywords):\n",
        "    query = '+'.join(keywords) + '+in:readme+in:description'\n",
        "    result = g.search_repositories(query, 'stars', 'desc')\n",
        "\n",
        "    print(f'Found {result.totalCount} repo(s)')\n",
        "\n",
        "    for repo in result:\n",
        "        print(repo.clone_url)\n"
      ],
      "metadata": {
        "id": "V3r2gNjjM1cF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}