{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Non_Representative_Statistics_Estimation_Smells.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1XEhbtlu5GwZ3YsvePw8HRJQPIsKgOHtb",
      "authorship_tag": "ABX9TyOzz3PxUfgunfr+cvIA1jdL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeedsiddik/dl_design_smells/blob/main/Non_Representative_Statistics_Estimation_Smells.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D1N4nB_IkXj4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "import glob, os\n",
        "import pandas as pd\n",
        "from fnmatch import fnmatch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to gDrive and get list of files"
      ],
      "metadata": {
        "id": "i8udyI7G0rEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmfjsPz3ksrP",
        "outputId": "0e8b07b2-f7cc-45b5-d84e-942cbbf1c278"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_path = \"/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/\""
      ],
      "metadata": {
        "id": "8ohfAw7WzNtC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_list_of_filename(path, extension):\n",
        "#     notebook_filenames_list = glob.glob(os.path.join(path, extension))\n",
        "    \n",
        "#     print(len(notebook_filenames_list))\n",
        "#     return notebook_filenames_list"
      ],
      "metadata": {
        "id": "PD-VtCVez2eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_of_filename(root, extension):\n",
        "    notebook_filenames_list = []\n",
        "\n",
        "    for path, subdirs, files in os.walk(root):\n",
        "        for name in files:\n",
        "            if fnmatch(name, extension):\n",
        "                notebook_filenames_list.append(os.path.join(path, name))\n",
        "\n",
        "    return notebook_filenames_list"
      ],
      "metadata": {
        "id": "xcQtv-JgnjkH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_py_files = get_list_of_filename(gdrive_path+\"data/\", \"*.py\")\n",
        "list_of_py_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEzJVWbzz6jR",
        "outputId": "9fa04525-ba96-4763-86cb-4b97bbacbaa7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so34716454.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so55776436_2.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so55776436_3.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so55776436_1.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/kanul$-android-tensorflow_sr$tensorflow$contrib$keras$python$keras$applications$inception_v3.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/configuration.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/data_augmentation.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/data_load.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/feature_extraction.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/run.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/train.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/utils.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Michael-Raafat/src/visualize.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Ramtin-Nouri/customLogger.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Ramtin-Nouri/dataManager.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Ramtin-Nouri/train.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Ramtin-Nouri/nets/CNN.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/shawn2030/gather_images.py.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/shawn2030/play_the_game.py.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/shawn2030/test.py.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/shawn2030/train_model.py.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Be997398715/model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Be997398715/pruning.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Be997398715/util.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/pkicsiny/src/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/pkicsiny/src/data_augmentation.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/pkicsiny/src/data_import.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/pkicsiny/src/loss_functions.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/pkicsiny/src/metrics.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/pkicsiny/src/networks.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/pkicsiny/src/preprocessing.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/pkicsiny/src/utils.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/pkicsiny/src/visualisation.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/harish-raviprakash/customLayers2.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/harish-raviprakash/loadData.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/harish-raviprakash/modelFiles2.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/harish-raviprakash/rtfm_psdP2P_all.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/harish-raviprakash/train.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/cover.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/test.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/untitled.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/bean/User.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/ml/实用数据挖掘/2/io module/report.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/ml/实用数据挖掘/2/io module/source/daily.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/ml/实用数据挖掘/2/io module/source/weekly.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/server/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/server/models.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/conv_train.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/01-TF2.0-Overview/conv_train.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/01-TF2.0-Overview/fc_train.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/02-AutoGraph/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/03-Play-with-MNIST/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/04-Linear-Regression/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/05-FashionMNIST/mnist_Seqential_gradient.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/05-FashionMNIST/mnist_custommodel.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/05-FashionMNIST/mnist_fit.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/05-FashionMNIST/mnist_matmul.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/06-CIFAR-VGG/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/06-CIFAR-VGG/network.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/07-Inception/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/08-ResNet/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/09-RNN-Sentiment-Analysis/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/10-ColorBot/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/10-ColorBot/model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/10-ColorBot/utils.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/11-AE/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/12-VAE/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/13-DCGAN/gan.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/13-DCGAN/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/14-Pixel2Pixel/gd.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/14-Pixel2Pixel/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/15-CycleGAN/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/15-CycleGAN/model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/inspect_model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/roi_test.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/train_model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/visualize.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/core/anchor/anchor_generator.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/core/anchor/anchor_target.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/core/bbox/bbox_target.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/core/bbox/geometry.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/core/bbox/transforms.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/core/loss/losses.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/datasets/coco.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/datasets/data_generator.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/datasets/transforms.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/datasets/utils.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/models/backbones/resnet.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/models/bbox_heads/bbox_head.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/models/detectors/faster_rcnn.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/models/detectors/test_mixins.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/models/necks/fpn.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/models/roi_extractors/roi_align.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/models/rpn_heads/rpn_head.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/16-fasterRCNN/detection/utils/misc.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/17-A2C/a2c.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/18-GPT/model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/bert.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/loader.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/main.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/tokenizer.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/embedding_similarity/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/embedding_similarity/embeddings.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/layer_normalization/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/layer_normalization/layer_normalization.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/layers/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/layers/conv.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/layers/embedding.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/layers/extract.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/layers/inputs.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/layers/masked.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/layers/pooling.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/multi_head_attention/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/multi_head_attention/multi_head.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/multi_head_attention/multi_head_attention.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/pointwise_feedforward/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/pointwise_feedforward/feed_forward.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/position_embedding/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/position_embedding/pos_embd.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/position_embedding/trig_pos_embd.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/self_attention/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/self_attention/scaled_dot_attention.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/self_attention/seq_self_attention.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/self_attention/seq_weighted_attention.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/transformer/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/transformer/gelu.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/19-BERT/transformer/transformer.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/20-GCN/config.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/20-GCN/inits.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/20-GCN/layers.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/20-GCN/metrics.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/20-GCN/models.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/20-GCN/train.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/20-GCN/utils.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/21-CN-EN-Translation-BERT/attention.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/21-CN-EN-Translation-BERT/attlayer.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/21-CN-EN-Translation-BERT/bert_train.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/21-CN-EN-Translation-BERT/bertmodel.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/21-CN-EN-Translation-BERT/test.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/21-CN-EN-Translation-BERT/tokenizer.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/21-CN-EN-Translation-BERT/transformer.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/21-CN-EN-Translation-BERT/transformer_train.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ATai2/tensorflow/21-CN-EN-Translation-BERT/utils.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/create_multi_model_submition.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/create_submission.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/create_submission_ensemble.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/create_submission_ensemble_avg.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/create_submission_ensemble_avg_per_cls.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/create_submission_ensemble_nn.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/data_augmentation.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/data_augmentation_full.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/data_augmentation_npz.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/dump_best_models.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/dump_test_predictions.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/evaluate_ensemble.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/evaluate_multi_topology.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/evaluate_network.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/extract_features.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/optimize_models.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/print_models.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/train_network.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/model/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/model/model_factory.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/model/resnet_152_keras.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/utils/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/utils/data_utils.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/ynahshan/utils/gpu_utils.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/display.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/metrics.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/preprocess.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/trainer.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/models/As2s_gru.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/models/As2s_lstm.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/models/gru.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/models/lstm.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/models/resnet.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/models/s2s_gru.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/models/s2s_lstm.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/BDouchet/models/vgg.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/setup.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/bin/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/bin/gen_windows.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/__init__.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/gdal2tiles.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/gdal2tiles2.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/gdal2tiles_multiprocess.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/gdal_merge.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/gdal_polygonize.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/image.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/image_generator.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/image_tools.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/make_overlays.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/match_dirc.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/mosaic.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/residual_segnet_model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/resize.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/seg_resnet_model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/segnet_model.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/segtools.py',\n",
              " '/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tonychang-cspinc/src/strider.py']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detect BatchNormalization and Dropout in DL Code "
      ],
      "metadata": {
        "id": "Nzj9YDfX0w3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name_list, code_line_list, line_number_list = [], [], []\n",
        "for filename in list_of_py_files:\n",
        "    try:\n",
        "        with open(filename) as fp:\n",
        "            is_dl_project = False\n",
        "            line_number = 0\n",
        "            \n",
        "            lines = fp.readlines()\n",
        "            for line in lines:\n",
        "                line_number += 1\n",
        "                line = line.strip()\n",
        "                if re.match(r'^from |import ', line):\n",
        "                    package_name = line.split()[1].split('.')[0]\n",
        "                    if re.match(r'keras|tensorflow', package_name):\n",
        "                        is_dl_project = True\n",
        "                \n",
        "                if (is_dl_project):\n",
        "                    if (\"BatchNormalization()\" in line) or (\"Dropout(\" in line):\n",
        "                        file_name_list.append(filename)\n",
        "                        code_line_list.append(line)\n",
        "                        line_number_list.append(line_number)\n",
        "                        \n",
        "                        # print (filename, line_number, line)\n",
        "    except Exception as e:\n",
        "        print(\"Error : \", filename, \"; \", str(e))\n",
        "        pass \n"
      ],
      "metadata": {
        "id": "61jUVs6p0K7E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Filename':file_name_list, 'Code': code_line_list, 'LineNumber':line_number_list}\n",
        "df_dl_smell = pd.DataFrame(data)\n",
        "df_dl_smell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fLqCDjPV0MxF",
        "outputId": "36f9617e-be51-4896-9448-9fb837c487f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Filename  \\\n",
              "0    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "1    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "2    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "3    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "4    /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "..                                                 ...   \n",
              "937  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "938  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "939  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "940  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "941  /content/gdrive/MyDrive/Colab_Notebooks/ECE720...   \n",
              "\n",
              "                                Code  LineNumber  \n",
              "0    model.add(BatchNormalization())          12  \n",
              "1            model.add(Dropout(0.5))          14  \n",
              "2    model.add(BatchNormalization())          18  \n",
              "3            model.add(Dropout(0.5))          20  \n",
              "4    model.add(BatchNormalization())          24  \n",
              "..                               ...         ...  \n",
              "937            BatchNormalization(),          94  \n",
              "938            BatchNormalization(),          98  \n",
              "939           Dropout(dropout_rate),         102  \n",
              "940            BatchNormalization(),         105  \n",
              "941            BatchNormalization(),         109  \n",
              "\n",
              "[942 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f58af69-d00e-4cb0-bcb0-c7b52c02b448\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Code</th>\n",
              "      <th>LineNumber</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(BatchNormalization())</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(Dropout(0.5))</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(BatchNormalization())</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(Dropout(0.5))</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>model.add(BatchNormalization())</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>BatchNormalization(),</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>BatchNormalization(),</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>Dropout(dropout_rate),</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>BatchNormalization(),</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>/content/gdrive/MyDrive/Colab_Notebooks/ECE720...</td>\n",
              "      <td>BatchNormalization(),</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>942 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f58af69-d00e-4cb0-bcb0-c7b52c02b448')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f58af69-d00e-4cb0-bcb0-c7b52c02b448 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f58af69-d00e-4cb0-bcb0-c7b52c02b448');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.unique(df_dl_smell['Filename'])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UEGW87QR1G_I",
        "outputId": "c4eccf3e-58a7-4eac-e399-b84880622fce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so34716454.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AST Python"
      ],
      "metadata": {
        "id": "w1JikkWo0jRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "from pprint import pprint\n",
        "\n",
        "# from find_call import FindCall\n",
        "from ast import NodeVisitor, literal_eval"
      ],
      "metadata": {
        "id": "VonXjJ7L0n62"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FindCall(NodeVisitor):\n",
        "    def __init__(self, *args):\n",
        "        if len(args) < 1:\n",
        "            raise ValueError(\"No target function (need at least one)\")\n",
        "        self.result = {arg: []for arg in args}\n",
        "\n",
        "    def visit_Call(self, node):\n",
        "        if hasattr(node.func, \"id\") and (node.func.id in self.result):\n",
        "            self.result[node.func.id].append([node.lineno])\n",
        "        # visit the children\n",
        "        self.generic_visit(node)"
      ],
      "metadata": {
        "id": "GI02Xjdj0rQ8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(pd.unique(df_dl_smell['Filename'])[0]) as f:\n",
        "    lines = f.readlines()\n",
        "content = ''.join(lines)\n",
        "\n",
        "lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW6uSXAD1TRw",
        "outputId": "5f55d6d2-4fec-44bb-a318-4bff30a21971"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['# import BatchNormalization\\n',\n",
              " 'from tensorflow.keras.layers import BatchNormalization\\n',\n",
              " 'from keras.models import Sequential\\n',\n",
              " 'from tensorflow.keras.layers import Dense\\n',\n",
              " 'import tensorflow as ts\\n',\n",
              " '\\n',\n",
              " '# instantiate model\\n',\n",
              " 'model = Sequential()\\n',\n",
              " '\\n',\n",
              " '# we can think of this chunk as the input layer\\n',\n",
              " \"model.add(Dense(64, input_dim=14, init='uniform'))\\n\",\n",
              " 'model.add(BatchNormalization())\\n',\n",
              " \"model.add(Activation('tanh'))\\n\",\n",
              " 'model.add(Dropout(0.5))\\n',\n",
              " '\\n',\n",
              " '# we can think of this chunk as the hidden layer    \\n',\n",
              " \"model.add(Dense(64, init='uniform'))\\n\",\n",
              " 'model.add(BatchNormalization())\\n',\n",
              " \"model.add(Activation('tanh'))\\n\",\n",
              " 'model.add(Dropout(0.5))\\n',\n",
              " '\\n',\n",
              " '# we can think of this chunk as the output layer\\n',\n",
              " \"model.add(Dense(2, init='uniform'))\\n\",\n",
              " 'model.add(BatchNormalization())\\n',\n",
              " \"model.add(Activation('softmax'))\\n\",\n",
              " '\\n',\n",
              " '# setting up the optimization of our weights \\n',\n",
              " 'sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\\n',\n",
              " \"model.compile(loss='binary_crossentropy', optimizer=sgd)\\n\",\n",
              " '\\n',\n",
              " '# running the fitting\\n',\n",
              " 'model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_py_files = get_list_of_filename(gdrive_path+\"data/\", \"*.py\")\n",
        "list_of_py_files"
      ],
      "metadata": {
        "id": "SiLsA89XSPfk"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method_names = [\"BatchNormalization\", \"Dropout\"]\n",
        "\n",
        "list_of_ast_filenames = []\n",
        "list_of_ast_method_dict = []\n",
        "\n",
        "for file_name in list_of_py_files:\n",
        "    try:\n",
        "        file = open(file_name, 'r')\n",
        "        ast_data = ast.parse(file.read())\n",
        "\n",
        "        intra_file_ast_method_dict = []\n",
        "        atleast_one_methods_used = True\n",
        "\n",
        "        for method_name in method_names:\n",
        "            fc = FindCall(method_name)\n",
        "            fc.visit(ast_data)\n",
        "            # print (fc.result.keys())\n",
        "            # print ((\"Keys %s: Values %s, Len %s\")%(fc.result.keys(), fc.result.values(), len(fc.result.values() ) ))\n",
        "\n",
        "            atleast_one_methods_used = bool([a for a in fc.result.values() if a != []])\n",
        "                \n",
        "            intra_file_ast_method_dict.append(fc.result)\n",
        "\n",
        "        if(atleast_one_methods_used):\n",
        "            list_of_ast_filenames.append(file_name)\n",
        "            list_of_ast_method_dict.append(intra_file_ast_method_dict)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print (\"Problem in AST: Filename \" + file_name + \":  \" + str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo1C1OXGC6Te",
        "outputId": "6a889234-c011-404f-d23a-246639326ece"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem in AST: Filename /content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Deep-Learning-for-ECoG.git/rtfm_psdP2P_all.py:  invalid syntax (<unknown>, line 114)\n",
            "Problem in AST: Filename /content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Forecasting-Air-Pollutant-Concentration-in-Lille.git/preprocess.py:  unexpected indent (<unknown>, line 13)\n",
            "Problem in AST: Filename /content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Forecasting-Air-Pollutant-Concentration-in-Lille.git/trainer.py:  invalid syntax (<unknown>, line 22)\n",
            "Problem in AST: Filename /content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tws-segnet.git/src/gdal2tiles.py:  Missing parentheses in call to 'print'. Did you mean print('You are using \"old gen\" bindings. gdal2tiles needs \"new gen\" bindings.')? (<unknown>, line 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p4UNBb2FecqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_wise_method_line, ast_filename in zip(list_of_ast_method_dict, list_of_ast_filenames):\n",
        "    print (ast_filename)\n",
        "    for method_line_dict in file_wise_method_line:\n",
        "        for key, value in method_line_dict.items():\n",
        "            print (key, len(value), value)"
      ],
      "metadata": {
        "id": "ijtJw9nReWVe",
        "outputId": "30408569-e2cf-468b-c25f-678a6ff88b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so34716454.py\n",
            "BatchNormalization 3 [[12], [18], [24]]\n",
            "Dropout 2 [[14], [20]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so55776436_2.py\n",
            "BatchNormalization 1 [[7]]\n",
            "Dropout 1 [[6]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so55776436_3.py\n",
            "BatchNormalization 0 []\n",
            "Dropout 2 [[3], [6]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/so55776436_1.py\n",
            "BatchNormalization 1 [[7]]\n",
            "Dropout 1 [[6]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Music-Artist-Classifier.git/src/model.py\n",
            "BatchNormalization 75 [[17], [20], [24], [27], [31], [34], [39], [49], [52], [56], [59], [63], [66], [72], [83], [87], [92], [96], [101], [107], [118], [121], [125], [128], [132], [137], [147], [150], [154], [157], [161], [166], [176], [179], [183], [186], [190], [193], [197], [201], [206], [228], [232], [236], [247], [251], [255], [266], [270], [274], [285], [289], [293], [296], [307], [311], [315], [319], [330], [334], [338], [342], [353], [357], [361], [365], [376], [380], [384], [388], [426], [428], [436], [439], [443]]\n",
            "Dropout 24 [[70], [74], [85], [89], [94], [98], [103], [109], [269], [273], [310], [314], [318], [333], [337], [341], [356], [360], [364], [379], [383], [387], [401], [414]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/EyeFixationPrediction.git/nets/CNN.py\n",
            "BatchNormalization 32 [[23], [28], [33], [38], [43], [48], [53], [58], [63], [68], [73], [78], [84], [86], [88], [92], [97], [102], [107], [113], [118], [123], [128], [134], [139], [144], [149], [157], [159], [161], [163], [165]]\n",
            "Dropout 24 [[25], [30], [35], [39], [45], [50], [55], [59], [65], [70], [75], [79], [94], [99], [104], [109], [115], [120], [125], [130], [136], [141], [146], [151]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Rock-Paper-Scissor.git/train_model.py.py\n",
            "BatchNormalization 16 [[64], [69], [74], [79], [84], [89], [96], [100], [104], [108], [112], [116], [120], [124], [128], [132]]\n",
            "Dropout 16 [[66], [71], [76], [81], [86], [91], [97], [101], [105], [109], [113], [117], [121], [125], [129], [133]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/keras_pruning.git/model.py\n",
            "BatchNormalization 14 [[28], [33], [39], [44], [50], [55], [60], [67], [72], [77], [84], [89], [94], [102]]\n",
            "Dropout 10 [[29], [40], [51], [56], [68], [73], [85], [90], [97], [104]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/kaggle_planet_competition.git/model/model_factory.py\n",
            "BatchNormalization 103 [[24], [31], [36], [81], [84], [87], [90], [98], [101], [104], [112], [115], [130], [323], [342], [361], [364], [383], [402], [421], [488], [519], [544], [569], [594], [619], [644], [658], [684], [701], [718], [735], [925], [980], [1017], [1054], [1091], [1128], [1165], [1203], [1245], [1279], [1313], [1342], [1346], [1355], [1395], [1435], [1475], [1518], [1546], [1582], [1590], [1592], [1598], [1604], [1610], [1616], [1623], [1631], [1635], [1641], [1647], [1653], [1664], [1672], [1676], [1682], [1688], [1705], [1713], [1748], [1757], [1790], [1799], [1832], [1842], [1863], [1874], [1895], [1906], [1933], [1944], [1977], [1988], [2021], [2032], [2071], [2082], [2111], [2122], [2151], [2162], [2191], [2200], [2226], [2236], [2262], [2266], [2276], [2302], [2306], [2316]]\n",
            "Dropout 227 [[18], [25], [126], [131], [287], [292], [302], [307], [324], [343], [362], [365], [384], [403], [422], [489], [520], [545], [570], [595], [620], [645], [659], [661], [685], [687], [702], [704], [719], [721], [736], [759], [782], [805], [892], [914], [985], [990], [995], [1000], [1022], [1027], [1032], [1037], [1059], [1064], [1069], [1074], [1096], [1101], [1106], [1111], [1133], [1138], [1143], [1148], [1170], [1175], [1180], [1185], [1208], [1213], [1218], [1250], [1255], [1260], [1265], [1284], [1289], [1294], [1299], [1317], [1322], [1327], [1332], [1337], [1343], [1347], [1360], [1365], [1370], [1375], [1380], [1385], [1400], [1405], [1410], [1415], [1420], [1425], [1440], [1445], [1450], [1455], [1460], [1465], [1480], [1485], [1490], [1495], [1500], [1505], [1522], [1527], [1532], [1537], [1542], [1547], [1558], [1563], [1568], [1573], [1578], [1583], [1595], [1601], [1607], [1613], [1619], [1624], [1636], [1642], [1648], [1654], [1660], [1665], [1677], [1683], [1689], [1695], [1701], [1706], [1718], [1723], [1728], [1733], [1738], [1743], [1749], [1761], [1766], [1771], [1776], [1781], [1786], [1791], [1803], [1808], [1813], [1818], [1823], [1828], [1833], [1847], [1853], [1859], [1864], [1879], [1885], [1891], [1896], [1911], [1917], [1923], [1929], [1934], [1949], [1955], [1961], [1967], [1973], [1978], [1993], [1999], [2005], [2011], [2017], [2022], [2037], [2043], [2049], [2055], [2061], [2067], [2072], [2087], [2092], [2097], [2102], [2107], [2112], [2127], [2132], [2137], [2142], [2147], [2152], [2167], [2172], [2177], [2182], [2187], [2192], [2204], [2208], [2212], [2216], [2221], [2227], [2240], [2244], [2248], [2252], [2257], [2263], [2267], [2280], [2284], [2288], [2292], [2297], [2303], [2307], [2320], [2324], [2328], [2332]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Forecasting-Air-Pollutant-Concentration-in-Lille.git/models/resnet.py\n",
            "BatchNormalization 3 [[21], [31], [40]]\n",
            "Dropout 4 [[14], [22], [32], [41]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/Forecasting-Air-Pollutant-Concentration-in-Lille.git/models/vgg.py\n",
            "BatchNormalization 6 [[13], [17], [23], [27], [33], [37]]\n",
            "Dropout 6 [[14], [18], [24], [28], [34], [38]]\n",
            "/content/gdrive/MyDrive/Colab_Notebooks/ECE720_MLSE/data/tws-segnet.git/src/segnet_model.py\n",
            "BatchNormalization 14 [[33], [37], [44], [48], [55], [59], [66], [73], [83], [87], [94], [98], [105], [109]]\n",
            "Dropout 7 [[40], [51], [62], [69], [80], [91], [102]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GitHub Clone for Dataset  "
      ],
      "metadata": {
        "id": "_VlRxivJ08XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install PyGithub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f66SeAuB1OuS",
        "outputId": "691f6415-c19f-4e5f-fa78-9ae29e15d6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.9 gitpython-3.1.27 smmap-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gitpython"
      ],
      "metadata": {
        "id": "BHyzawQUjliF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98359eb-af6a-4953-a229-16c816860415"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 71 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 102 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 133 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 143 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 174 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 181 kB 22.3 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30 kB 49.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 40 kB 54.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51 kB 58.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 61 kB 64.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.9 gitpython-3.1.27 smmap-5.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from git import Repo\n",
        "import shutil"
      ],
      "metadata": {
        "id": "JQzckUAmjbNg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (os.path.isdir(gdrive_path+\"/data/\"+\"test\"))\n",
        "if (os.path.isdir(gdrive_path+\"/data/\"+\"test\")):\n",
        "    shutil.rmtree(gdrive_path+\"/data/\"+\"test\") \n",
        "\n",
        "print (os.path.isdir(gdrive_path+\"/data/\"+\"test\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Oz2InIQut0j",
        "outputId": "a054353c-8b6f-4acf-8f26-9f6cdc1a9a00"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(gdrive_path+'/data/github_data_link.txt', 'r')\n",
        "lines = file.readlines()\n",
        "\n",
        "for git_url in lines:\n",
        "    try:\n",
        "        git_url = git_url.strip()\n",
        "        repo_dir = gdrive_path+\"/data/\"+git_url.split(\"/\")[-1]\n",
        "\n",
        "        # remove the directory if it already exists and replace wit the new one\n",
        "        if (os.path.isdir(repo_dir)):\n",
        "            shutil.rmtree(repo_dir) \n",
        "\n",
        "        Repo.clone_from(git_url, repo_dir)\n",
        "    except Exception as e:\n",
        "        print (\"Error in \"+ git_url + \"; \" + e)"
      ],
      "metadata": {
        "id": "9Snw4ZbemFAh"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------- Practice ------------ "
      ],
      "metadata": {
        "id": "zT5k-TBVTvej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "from pprint import pprint\n",
        "\n",
        "import requests\n",
        "from github import Github\n",
        "from github.GithubException import RateLimitExceededException\n",
        "from github.GithubObject import GithubObject\n",
        "from github.PaginatedList import PaginatedList"
      ],
      "metadata": {
        "id": "HnrDTyon1B2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACCESS_TOKEN = \"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\""
      ],
      "metadata": {
        "id": "4fw6lYr340cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAGE_SIZE = 1\n",
        "g = Github(ACCESS_TOKEN, per_page=PAGE_SIZE)"
      ],
      "metadata": {
        "id": "4iMtfFq545eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wait():\n",
        "    rate = g.get_rate_limit().search\n",
        "    reset_utc_timestamp = rate.reset.timestamp()\n",
        "    now_utc_timestamp = datetime.datetime.utcnow().timestamp()\n",
        "    sleep_time = (reset_utc_timestamp - now_utc_timestamp) + 5  # 5s buffer time\n",
        "    print(f\"Waiting {sleep_time}s to pass rate limit\")\n",
        "    time.sleep(sleep_time)"
      ],
      "metadata": {
        "id": "Pdov8Az7496O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filename(file: GithubObject):\n",
        "    filename = os.path.join(file.repository.full_name, file.path)\n",
        "    filename = filename.replace('/', '$')\n",
        "    return filename.replace('\\\\', '$')"
      ],
      "metadata": {
        "id": "5jAE7f9a4_4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_file(url: str, filename: str, count: int):\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "    directory = gdrive_path + \"data/\"\n",
        "    if not os.path.exists(directory):\n",
        "        print(\"Path doesn't exists\")\n",
        "        os.mkdir(directory)\n",
        "\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    print(f\"[{count}] Saving {full_path}\")\n",
        "    open(full_path, 'wb').write(r.content)"
      ],
      "metadata": {
        "id": "pvDeWHc75Bz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.exists(gdrive_path + \"data/\")"
      ],
      "metadata": {
        "id": "LfxX0xgXATv1",
        "outputId": "a3c443fd-979f-4a11-977f-6d5bcd85f67e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_files_of_page(codes, page_index, count):\n",
        "    page_codes = codes.get_page(page_index)\n",
        "    print(f\"{len(page_codes)} results in page {page_index+1}\")\n",
        "\n",
        "    for code in page_codes:\n",
        "        count += 1\n",
        "        save_file(code.download_url, get_filename(code), count)\n",
        "\n",
        "    return "
      ],
      "metadata": {
        "id": "UH_bBriJ6rcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repositories = g.search_repositories(query='keras in:file extension:py language:python')\n",
        "# print (repositories.size())\n",
        "for repo in repositories:\n",
        "    print(repo)"
      ],
      "metadata": {
        "id": "ruWAXS_yCOku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the user provides the input you need to split into a list: Here, you are splitting the keywords provided and trimming them of any unnecessary white-space. Python’s list comprehensions enable you to perform all this in one line."
      ],
      "metadata": {
        "id": "b4CR2b9uNCQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = \"keras, tensorflow, BatchNormalization, Dropout\"\n",
        "# keywords =  \"french, german\"\n",
        "keywords = [keyword.strip() for keyword in keywords.split(',')]\n",
        "print(keywords)"
      ],
      "metadata": {
        "id": "cXWUoDbyK7x_",
        "outputId": "6b3efbfe-63db-43ce-a675-23bca1bed941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['keras', 'tensorflow', 'BatchNormalization', 'Dropout']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you need to add a function that will receive the keywords and search GitHub for repos that match."
      ],
      "metadata": {
        "id": "ZDyI646eNLXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There’s a couple of things happening in this function. First of all, you are taking the keywords and forming a GitHub search query. GitHub search queries taking the following format.\n",
        "\n",
        "SEARCH_KEYWORD_1+SEARCH_KEYWORD_N+QUALIFIER_1+QUALIFIER_N\n"
      ],
      "metadata": {
        "id": "PV2JWeJmNpas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_github(keywords):\n",
        "    query = '+'.join(keywords) + '+in:readme+in:description'\n",
        "    result = g.search_repositories(query, 'stars', 'desc')\n",
        "\n",
        "    print(f'Found {result.totalCount} repo(s)')\n",
        "\n",
        "    for repo in result:\n",
        "        print(repo.clone_url)\n"
      ],
      "metadata": {
        "id": "V3r2gNjjM1cF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}